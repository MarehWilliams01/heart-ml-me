{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cVwzqb_t3xDtg7Ns-aCtmZxNVSMcBAYW",
      "authorship_tag": "ABX9TyOBoDjdRUtMryYLjXKckN2f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarehWilliams01/heart-ml-me/blob/main/heart_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the neccesary libraries"
      ],
      "metadata": {
        "id": "wTA-R2p81q6D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBkHTAV0niYx"
      },
      "outputs": [],
      "source": [
        "#importing the neccessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm, metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split, cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loading the datset"
      ],
      "metadata": {
        "id": "D2lFhSybJqa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/shuffled_data_with_features.csv'\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "051UuDwyDHON",
        "outputId": "0154bbd5-e5a7-439c-ca61-8a68388ed5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# creating the training and the test data"
      ],
      "metadata": {
        "id": "Qd4koyGqKLkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#changing the '?' in the dataset to Nan so that python can identify it as a missing value\n",
        "data.replace('?', np.nan, inplace=True)\n",
        "\n",
        "#selecting the columns with missing values\n",
        "columns_with_missing = ['trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
        "\n",
        "#converting columns with missing vales to numeric\n",
        "data[columns_with_missing] = data[columns_with_missing].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "#splitting the data into X and y\n",
        "X = data.drop(\"num\", axis=1)\n",
        "y = data[\"num\"]\n",
        "\n",
        "#separating them into train and test data\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "JCPARvAb2pzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **filling up missing data**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b4Yr1duYR8w5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **mean value**\n",
        ">> **don't run this before knn!!**\n",
        "\n"
      ],
      "metadata": {
        "id": "JTI2qQyVwLnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filling missing values in each column\n",
        "for column in columns_with_missing:\n",
        "  mean = data[column].mean()\n",
        "  data[column].fillna(mean, inplace=True)\n",
        "\n",
        "#print the data head\n",
        "print(data.head(10))"
      ],
      "metadata": {
        "id": "XUkuHY4VwZN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **k-NN**\n",
        "\n"
      ],
      "metadata": {
        "id": "Vo-yeYPo8s37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the range of k values to test\n",
        "k_values = range(1, 41)\n",
        "\n",
        "#storing performance results\n",
        "svm_scores = []\n",
        "bn_scores = []\n",
        "\n",
        "#iteration\n",
        "for k in k_values:\n",
        "  #creating a copy of the training sets for imputation\n",
        "  impute_x_train = x_train.copy()\n",
        "  impute_x_test = x_test.copy()\n",
        "\n",
        "  #initializing the KNN imputer with the right value of k\n",
        "  imputer = KNNImputer(n_neighbors=k)\n",
        "\n",
        "  #fit the imputer on the training set to transform the training and testing sets\n",
        "  impute_x_train = pd.DataFrame(imputer.fit_transform(impute_x_train), columns=x_train.columns)\n",
        "  impute_x_test = pd.DataFrame(imputer.fit_transform(impute_x_test), columns=x_test.columns)\n",
        "\n",
        "  #training the svm model to identify the accuracies of each k\n",
        "  svm_classifier= SVC()\n",
        "  svm_classifier.fit(impute_x_train, y_train)\n",
        "  svm_pred = svm_classifier.predict(impute_x_test)\n",
        "  svm_scores.append(accuracy_score(y_test, svm_pred))\n",
        "\n",
        "  #using bn classifier and calculating the accuracy using cross-validation\n",
        "  bn_classifier = GaussianNB()\n",
        "  bn_scores.append(np.mean(cross_val_score(bn_classifier, impute_x_train, y_train, cv=10)))\n",
        "\n",
        "# Print the performance scores for each value of k\n",
        "for k, svm_score, bn_score in zip(k_values, svm_scores, bn_scores):\n",
        "    print(f\"K = {k}: SVM Accuracy = {svm_score}, BN Accuracy = {bn_score}\")\n",
        "\n",
        "#finding the best k value\n",
        "best_k_index = np.argmax(np.add(svm_scores, bn_scores))\n",
        "best_k = k_values[best_k_index]\n",
        "best_svm_score = svm_scores[best_k_index]\n",
        "best_bn_score = bn_scores[best_k_index]\n",
        "print(f\"Best k: {best_k}\")\n",
        "print(f\"SVM Accuracy: {best_svm_score}\")\n",
        "print(f\"BN Accuracy: {best_bn_score}\")\n",
        "\n",
        "#printing the graph\n",
        "plt.plot(k_values, svm_scores, label='SVM Accuracy')\n",
        "plt.plot(k_values, bn_scores, label='BN Scores')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy Scores for Different k Values')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1AKkypdAJred"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**MICE**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "77J1PJGenSC1"
      }
    }
  ]
}